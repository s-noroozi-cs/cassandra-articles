Architecture Requirements of Cassandra
	Cassandra was designed to address many architecture requirements. 
	The most important requirement is to ensure there is no single point of failure. 
	This means that if there are 100 nodes in a cluster and a node fails, the cluster should continue to operate.

	This is in contrast to Hadoop where the namenode failure can cripple the entire system. 
	Another requirement is to have massive scalability so that a cluster can hold hundreds or thousands of nodes. 
	It should be possible to add a new node to the cluster without stopping the cluster.

	Further, the architecture should be highly distributed so that both processing and data can be distributed. 
	Also, high performance of read and write of data is expected so that the system can be used in real-time. 
	Let us explore the Cassandra architecture in the next section of the cassandra architecture tutorial.
	
Cassandra Architecture	
    - Cassandra is designed such that it has no master or slave nodes.
    - It has a ring-type architecture, that is, its nodes are logically distributed like a ring.
    - Data is automatically distributed across all the nodes.
    - Similar to HDFS, data is replicated across the nodes for redundancy.
    - Data is kept in memory and lazily written to the disk.
    - Hash values of the keys are used to distribute the data among nodes in the cluster.
	- Cassandra architecture supports multiple data centers.
	- Data can be replicated across data centers.
	
Effects of the Architecture
	Cassandra architecture enables transparent distribution of data to nodes. 
	This means you can determine the location of your data in the cluster based on the data. 
	Any node can accept any request as there are no masters or slaves. 
	If a node has the data, it will return the data. Else, it will send the request to the node that has the data.

	You can specify the number of replicas of the data to achieve the required level of redundancy. 
	For example, if the data is very critical, you may want to specify a replication factor of 4 or 5.
	If the data is not critical, you may specify just two. 
	
	It also provides tunable consistency, that is, the level of consistency can be specified as a trade-off with performance. 
	Transactions are always written to a commit log on disk so that they are durable. 
	
Cassandra Write Process
	The Cassandra write process ensures fast writes. Steps in the Cassandra write process are:
	
	1. Data is written to a commitlog on disk.
    2. The data is sent to a responsible node based on the hash value.
    3. Nodes write data to an in-memory table called memtable.
    4. From the memtable, data is written to an sstable in memory. 
	   Sstable stands for Sorted String table. This has a consolidated data of all the updates to the table.
    5. From the sstable, data is updated to the actual table.
    6. If the responsible node is down, data will be written to another node identified as tempnode. 
	The tempnode will hold the data temporarily till the responsible node comes alive.

	The diagram below [CassandraArchitecture_3.avif] depicts the write process when data is written to table A.
	
	Data is written to a commitlog on disk for persistence. It is also written to an in-memory memtable. 
	Memtable data is written to sstable which is used to update the actual table.
	
Rack
	The term ‘rack’ is usually used when explaining network topology. 
	A rack is a group of machines housed in the same physical box. 
	Each machine in the rack has its own CPU, memory, and hard disk. 
	However, the rack has no CPU, memory, or hard disk of its own.[CassandraArchitecture_4.avif]
	
	Features of racks are:
		- All machines in the rack are connected to the network switch of the rack
		- The rack’s network switch is connected to the cluster.
		- All machines on the rack have a common power supply. 
		  It is important to notice that a rack can fail due to two reasons: a network switch failure or a power supply failure.
		- If a rack fails, none of the machines on the rack can be accessed. So it would seem as though all the nodes on the rack are down.
	
Cassandra Read Process
	The Cassandra read process ensures fast reads. Read happens across all nodes in parallel. 
	If a node is down, data is read from the replica of the data. 
	Priority for the replica is assigned on the basis of distance. Features of the Cassandra read process are:

    - Data on the same node is given first preference and is considered data local.
    - Data on the same rack is given second preference and is considered rack local.
    - Data on the same data center is given third preference and is considered data center local.
    - Data in a different data center is given the least preference.

	Data in the memtable and sstable is checked first so that the data can be retrieved faster if it is already in memory.
	
Data Partitions
	Cassandra performs transparent distribution of data by horizontally partitioning the data in the following manner:
	- A hash value is calculated based on the primary key of the data.
    - The hash value of the key is mapped to a node in the cluster
    - The first copy of the data is stored on that node.
    - The distribution is transparent as you can both calculate the hash value and determine where a particular row will be stored.

	The following diagram depicts a four node cluster with token values of 0, 25, 50 and 75.[CassandraArchitecture_7.avif]
	
	For a given key, a hash value is generated in the range of 1 to 100. Keys with hash values in the range 
	1 to 25 are stored on the first node, 
	26 to 50 are stored on the second node, 
	51 to 75 are stored on the third node, and 
	76 to 100 are stored on the fourth node. 
	Please note that actual tokens and hash values in Cassandra are 127-bit positive integers.
	
Replication in Cassandra
	Replication refers to the number of replicas that are maintained for each row. 
	Replication provides redundancy of data for fault tolerance. 
	A replication factor of 3 means that 3 copies of data are maintained in the system.
	In this case, even if 2 machines are down, you can access your data from the third copy. 
	
	The default replication factor is 1. A replication factor of 1 means that a single copy of the data is maintained, 
	so if the node that has the data fails, you will lose the data.

	Cassandra allows replication based on nodes, racks, and data centers, 
	unlike HDFS that allows replication based on only nodes and racks. 
	Replication across data centers guarantees data availability even when a data center is down.
	
Network Topology
	Network topology refers to how the nodes, racks and data centers in a cluster are organized. 
	You can specify a network topology for your cluster as follows:
    - Specify in the Cassandra-topology.properties file.
    - Your data centers and racks can be specified for each node in the cluster.
    - Specify <ip-address>=<data center>:<rack name>.
    - For unknown nodes, a default can be specified.
    - You can also specify the hostname of the node instead of an IP address.

	An example of a topology configuration file.[CassandraArchitecture_8.avif]
	This file shows the topology defined for four nodes. The node with IP address 192.168.1.100 is mapped to data center DC1 and is present on the rack RAC1. 
	The node with IP address 192.168.2.200 is mapped to data center DC2 and is present on the rack RAC2.
	Similarly, the node with IP address 10.20.114.10 is mapped to data center DC2 and rack RAC1 and 
	the node with IP address 10.20.114.11 is mapped to data center DC2 and rack RAC1. 
	There is also a default assignment of data center DC1 and rack RAC1 so that any unassigned nodes will get this data center and rack.
	
	
	